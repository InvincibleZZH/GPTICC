{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T02:12:27.114643Z",
     "start_time": "2024-10-28T02:12:26.326201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from fairscale.nn.data_parallel import FullyShardedDataParallel as FSDP\n",
    "from fairscale.nn.wrap import enable_wrap, wrap\n",
    "import esm\n",
    "from esm import FastaBatchedDataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os.path\n",
    "import pickle as pk\n",
    "import lmdb\n",
    "import numpy as np\n",
    "import pickle"
   ],
   "id": "efcbd917fe6ab234",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T02:17:17.271651Z",
     "start_time": "2024-10-28T02:17:17.258417Z"
    }
   },
   "cell_type": "code",
   "source": "pwd",
   "id": "4956134b7403759c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/zzh/pycharm/GPTICC'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T02:17:41.146636Z",
     "start_time": "2024-10-28T02:17:41.140894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "fasta_file = './data/human_unreviewed.fasta'\n",
    "output_path = './data/temp.lmdb'"
   ],
   "id": "79f011ef256724b9",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "toks_per_batch = 12290\n",
    "dataset = FastaBatchedDataset.from_file(fasta_file)\n",
    "batches = dataset.get_batch_indices(toks_per_batch, extra_toks_per_seq=1)\n",
    "\n",
    "# init the distributed world with world_size 1\n",
    "url = \"tcp://localhost:23456\"\n",
    "torch.distributed.init_process_group(backend=\"nccl\", init_method=url, world_size=1, rank=0)\n",
    "\n",
    "# download model data from the hub\n",
    "model_name = \"esm2_t33_650M_UR50D\"\n",
    "model_data, regression_data = esm.pretrained._download_model_and_regression_data(model_name)\n",
    "\n",
    "# initialize the model with FSDP wrapper\n",
    "fsdp_params = dict(\n",
    "    mixed_precision=True,\n",
    "    flatten_parameters=True,\n",
    "    state_dict_device=torch.device(\"cpu\"),  # reduce GPU mem usage\n",
    "    cpu_offload=True,  # enable cpu offloading\n",
    ")\n",
    "with enable_wrap(wrapper_cls=FSDP, **fsdp_params):\n",
    "    model, vocab = esm.pretrained.load_model_and_alphabet_core(\n",
    "        model_name, model_data, regression_data\n",
    "    )\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, collate_fn=vocab.get_batch_converter(), batch_sampler=batches\n",
    "    )\n",
    "    model.eval()\n",
    "\n",
    "    # Wrap each layer in FSDP separately\n",
    "    for name, child in model.named_children():\n",
    "        if name == \"layers\":\n",
    "            for layer_name, layer in child.named_children():\n",
    "                wrapped_layer = wrap(layer)\n",
    "                setattr(child, layer_name, wrapped_layer)\n",
    "    model = wrap(model)\n",
    "\n",
    "\n",
    "sequence_representations = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (labels, strs, toks) in tqdm(enumerate(data_loader), total = len(data_loader)):\n",
    "        toks = toks.cuda()\n",
    "        toks = toks[:, :12288] #truncate\n",
    "        results = model(toks, repr_layers=[33], return_contacts=False)\n",
    "        token_representations = results[\"representations\"][33]\n",
    "        for i, label in enumerate(labels):\n",
    "            #print(label.split('|')[1])\n",
    "            truncate_len = min(12288, len(strs[i]))\n",
    "            sequence_representations.append((label.split('|')[1], token_representations[i, 1 : truncate_len + 1].mean(0).detach().cpu().numpy()))\n",
    "            torch.cuda.empty_cache()\n",
    "        if len(sequence_representations) >10000:\n",
    "            db = lmdb.open(\n",
    "                output_path,\n",
    "                map_size=2000 * (1024 * 1024 * 1024),  # 2000GB\n",
    "                create=True,\n",
    "                subdir=False,\n",
    "                readonly=False,  # Writable\n",
    "            )\n",
    "            with db.begin(write=True, buffers=True) as txn:\n",
    "                for (label,reprsentation) in sequence_representations:\n",
    "                    key = str(label).encode()\n",
    "                    reprsentation = pickle.dumps(reprsentation)\n",
    "\n",
    "                    txn.put(key=key, value=reprsentation)\n",
    "            db.close()\n",
    "            sequence_representations = []\n",
    "        if batch_idx==len(data_loader)-1:\n",
    "            db = lmdb.open(\n",
    "                output_path,\n",
    "                map_size=2000 * (1024 * 1024 * 1024),  # 2000GB\n",
    "                create=True,\n",
    "                subdir=False,\n",
    "                readonly=False,  # Writable\n",
    "            )\n",
    "            with db.begin(write=True, buffers=True) as txn:\n",
    "                for (label, reprsentation) in sequence_representations:\n",
    "                    key = str(label).encode()\n",
    "                    reprsentation = pickle.dumps(reprsentation)\n",
    "\n",
    "                    txn.put(key=key, value=reprsentation)\n",
    "            db.close()"
   ],
   "id": "9205727508355293"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4434e3b82662dc17"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
